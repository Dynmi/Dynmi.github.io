---
layout: post
comments: false
title:  "Diagonal Matrix and Orthogonal Matrix"
excerpt: "..."
date:   2022-01-06 00:37:00
mathjax: true
---

<script>
  MathJax = {
  tex: {
  inlineMath: [['$', '$']],
  displayMath: [['\\[', '\\]']],
  processEnvironments: true,
  processRefs: true
  },
  options: {
  skipHtmlTags: ['noscript', 'style', 'textarea', 'pre', 'code'],
  ignoreHtmlClass: 'tex2jax_ignore',
  renderActions: {
  find_script_mathtex: [10, function (doc) {
  for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
  const display = !!node.type.match(/; *mode=display/);
  const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
  const text = document.createTextNode('');
  node.parentNode.replaceChild(text, node);
  math.start = { node: text, delim: '', n: 0 };
  math.end = { node: text, delim: '', n: 0 };
  doc.math.push(math);
  }
  }, '']
  }
  },
  svg: {
  fontCache: 'global'
  }
  };
</script>
<script id="MathJax-script" async src="https://cdn.staticfile.org/mathjax/3.0.1/es5/tex-svg.js"></script>


# 以线性变换视角看矩阵

用$M_{m*n}$表示一个m行n列的矩阵。
建议您默认以列向量的视角来看一个矩阵。用$m_1$，$m_2$，…，$m_n$表示$M_{m*n}$的列向量。因此也可以用[$m_1$，$m_2$，…，$m_n$]表示$M_{m*n}$。
这里先选取简单情况：M为n*n的方阵。对于任意nx1的向量$a$，$b$ = $Ma$可以视为对$a$做了一个线性变换：将$a$的n个单位基向量分别拉伸到$m_1$，$m_2$，…，$m_n$，得到向量$b$。

# 最直白的矩阵——对角矩阵、正交矩阵

对角矩阵与正交矩阵都是方阵，因为运算便捷、可解释性强，很受人喜欢。
就像自然数是研究数论的基石一样，对角矩阵和正交矩阵就是研究线性代数的基石。

对角矩阵就很好理解了，即只对每个基向量进行压缩拉伸，而不扭转旋转。

正交矩阵，即对整组正交基保持原状作旋转，而不压缩拉伸。

正交矩阵有几个性质，它们将加速你遇到正交矩阵后的问题处理速度：
- $A^T =A^{-1}$
- $AA^T = A^TA = I$
- A的n个列向量都是单位向量且彼此正交
- A的n个行向量都是单位向量且彼此正交
- det(A) = 1（当然也就表示rank(A)为n）

这些都很好理解，而且证明过程很简单，这里就不写出来了。

# 对称矩阵的特征值分解

任意满秩方阵都可以进行特征值分解，这很简单就不在这里证明了。
实际应用中，出场率比较高的是对称矩阵。

对于对称矩阵M，必有正交矩阵A，使得$M=A_{n*n}*diag_{n}(\lambda)*A_{n*n}^{T}$。

即，任意对称矩阵的线性变换可以看作依次进行旋转变换$A^{T}$、伸缩变换$diag_{n}(\lambda)$、逆旋转变换$A$。

这是对以上的证明：
> **充要条件**：$M$为n行n列对称矩阵，|det(M)| > 0。
**得到结论**：存在正交矩阵$A$和对角矩阵$diag(\lambda)$，使得$M=A*diag_{n}(\lambda)*A^{-1}$
**证明过程**：
>>  如果满秩矩阵M是一个对称矩阵，那就是说$M=M^{T}$。
    那么就有$A^{T}M = A^{T}M^{T} = (MA)^{T} = (Adiag(\lambda))^{T} = diag(\lambda)A^{T}$，
    进而有$M = (A^{T})^{-1}diag(\lambda)A^{T}$
    结合$M=A_{n*n}*diag_{n}(\lambda)*A_{n*n}^{-1}$，即有$A^{T} = A^{-1}$。
    故A为正交矩阵，故$M=A_{n*n}*diag_{n}(\lambda)*A_{n*n}^{T}$

Ok，相信你已经能接受认可以上所述。我们从线性代数的角度找到了这个规律，那就可以在任何满足充要条件的场景下使用这个规律了。

[PageRank算法](https://zh.wikipedia.org/wiki/PageRank)

# 任意矩阵的奇异值分解

如果你学会了特征值分解，但没有听过奇异值分解，看到缺乏美感的非方阵，你一定会有这种灵感直觉：非方阵即m*n的矩阵，应该也能分解成对角矩阵和正交矩阵吧？ 
没错，接下来我们一起研究并证实确认你的直觉是对的。

任意线性变换都可以分解为：依次进行一个旋转变换、一个伸缩变换、一个旋转变换。
即，对于任意矩阵$M_{m*n}$，都存在正交矩阵$U_{m*m}$和$V_{n*n}$，伪对角矩阵$\Sigma_{m*n}$，使得$M=U \Sigma V^{T}$。

这里先给出这条规律的完整陈述和证明：
> **充要条件**：任意m*n的矩阵M
**得到结论**：存在正交矩阵$U_{m*m}$、正交矩阵$V_{n*n}$、伪对角矩阵$\Sigma_{m*n}$，$M=UBV^{T}$
**证明过程**：
>> 易证$(AB)^{T} = B^{T} A^{T}$，故有$(M^{T}M)^{T} = M^{T}M$。从这里看出$M^{T}M$是对称矩阵；
因此$M^{T}M$可以进行正交分解，即存在正交阵$U_{n*n}$和对角阵$diag_{n}(\lambda)$使得$M^{T}M = U_{n*n}^{T}\Sigma_{n*n}U_{n*n}$；
把上式进一步推导，存在正交阵$V_{m*m}$和伪对角矩阵$\Sigma_{m*n}$（满足$\Sigma \Sigma^{T} = diag_{n}(\lambda)$），使得$M^{T}M = U_{n*n}^{T} (\Sigma_{m*n})^{T} V_{m*m} V_{m*m}^{T} \Sigma_{m*n} U_{n*n}$；
从而有$M=U \Sigma V^{T}$

Ok，相信你已经能接受认可以上所述。我们从线性代数的角度找到了这个规律，那就可以在任何满足充要条件的场景下使用这个规律了。

利用$M_{m*n} = \sigma_{1} u_{1}^{T}v_{1} + \sigma_{2} u_{2}^{T}v_{2} + ... + \sigma_{n} u_{n}^{T}v_{n}$，就可以将$M_{m*n}$视为多项之和。因为$u$和$v$都是单位向量，那么$\sigma$大小就代表了这个项的权重占比。

[主成分分析](https://zh.wikipedia.org/zh-hans/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90)

[图像降噪](https://ieeexplore.ieee.org/abstract/document/7067415/)